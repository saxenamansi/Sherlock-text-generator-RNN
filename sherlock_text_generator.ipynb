{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "sherlock-text-generator.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaQ08dlCdDGp"
      },
      "source": [
        "## Reading the book content without header and footer section and writing the content to another text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2WHYmc-ie1l",
        "outputId": "6a8ae908-1cc4-428d-afbd-39920cbf5d00"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnvvm6RgdDHG"
      },
      "source": [
        "path = '/content/drive/MyDrive/Text Generation using Sherlock book/NLP task.txt'\n",
        "fhandle = open(path, encoding=\"utf8\")\n",
        "for line in fhandle:\n",
        "    if line.rstrip() == \"*** START OF THIS PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\":\n",
        "        break\n",
        "write_path = '/content/drive/MyDrive/Text Generation using Sherlock book/NLP_book.txt'\n",
        "output_file = open(write_path, 'w')\n",
        "for line in fhandle:\n",
        "    if line.rstrip() == \"*** END OF THIS PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\":\n",
        "        break;\n",
        "    output_file.write(line)   \n",
        "output_file.close()\n",
        "fhandle.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hex_CfD-dDHM",
        "outputId": "84590a76-5c8d-4aab-9b11-9c956c1d51a1"
      },
      "source": [
        "text = open(write_path, 'r', encoding='utf8').read()\n",
        "text = text.lower()\n",
        "unique_chars = set(text)\n",
        "\n",
        "print(\"Total number of characters in the book: \", len(text))\n",
        "print(\"Total number of words in the book: \", len(text.split()))\n",
        "print(\"Total number of unique characters:\" ,len(unique_chars))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of characters in the book:  562371\n",
            "Total number of words in the book:  104530\n",
            "Total number of unique characters: 62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qysYjY-sdDHU"
      },
      "source": [
        "char_dict = {}\n",
        "for index, char in enumerate(unique_chars):\n",
        "    char_dict[char] = index"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg2-djIYdDHZ",
        "outputId": "8180768d-5cac-4fae-8ff2-1ea8c2bdbdaa"
      },
      "source": [
        "char_dict.items()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('b', 0), ('q', 1), ('\\n', 2), ('y', 3), ('5', 4), ('v', 5), ('i', 6), ('w', 7), ('è', 8), ('l', 9), ('k', 10), ('é', 11), ('.', 12), ('œ', 13), ('’', 14), ('e', 15), ('8', 16), ('‘', 17), ('t', 18), ('à', 19), ('?', 20), (';', 21), ('&', 22), ('“', 23), ('u', 24), ('!', 25), ('4', 26), ('h', 27), ('f', 28), ('_', 29), (')', 30), ('æ', 31), (':', 32), ('-', 33), ('”', 34), ('c', 35), ('s', 36), ('0', 37), ('m', 38), ('r', 39), ('z', 40), (',', 41), ('£', 42), ('7', 43), ('a', 44), ('3', 45), ('½', 46), ('p', 47), ('â', 48), ('9', 49), ('o', 50), ('j', 51), ('2', 52), ('x', 53), (' ', 54), ('(', 55), ('d', 56), ('1', 57), ('g', 58), ('—', 59), ('6', 60), ('n', 61)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8H1M4EfOzsR"
      },
      "source": [
        "int_to_char_dict = {}\n",
        "for k, v in char_dict.items():\n",
        "  int_to_char_dict[v] = k"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqBlWW5hO9fM",
        "outputId": "4480bbf5-502c-46a1-a207-2edab4a4d333"
      },
      "source": [
        "int_to_char_dict.items()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(0, 'b'), (1, 'q'), (2, '\\n'), (3, 'y'), (4, '5'), (5, 'v'), (6, 'i'), (7, 'w'), (8, 'è'), (9, 'l'), (10, 'k'), (11, 'é'), (12, '.'), (13, 'œ'), (14, '’'), (15, 'e'), (16, '8'), (17, '‘'), (18, 't'), (19, 'à'), (20, '?'), (21, ';'), (22, '&'), (23, '“'), (24, 'u'), (25, '!'), (26, '4'), (27, 'h'), (28, 'f'), (29, '_'), (30, ')'), (31, 'æ'), (32, ':'), (33, '-'), (34, '”'), (35, 'c'), (36, 's'), (37, '0'), (38, 'm'), (39, 'r'), (40, 'z'), (41, ','), (42, '£'), (43, '7'), (44, 'a'), (45, '3'), (46, '½'), (47, 'p'), (48, 'â'), (49, '9'), (50, 'o'), (51, 'j'), (52, '2'), (53, 'x'), (54, ' '), (55, '('), (56, 'd'), (57, '1'), (58, 'g'), (59, '—'), (60, '6'), (61, 'n')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GYmgaLedDHg"
      },
      "source": [
        "## Training char-by-char with a sliding window of 80 characters at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_TM_XUIdDHl"
      },
      "source": [
        "window_len = 80\n",
        "input_seq = []\n",
        "output_seq = []\n",
        "for i in range(0, len(text) - window_len, 1):\n",
        "    seq_in = text[i:i + window_len]\n",
        "    seq_out = text[i + window_len]\n",
        "    input_seq.append([char_dict[char] for char in seq_in])\n",
        "    output_seq.append(char_dict[seq_out])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSV2QDT3dDHo",
        "outputId": "c172f1a1-f7eb-4e02-fd6f-6dd82d7a92a6"
      },
      "source": [
        "print(\"Length of input characters: \", len(input_seq))\n",
        "print(\"Length of output sequence: \", len(output_seq))\n",
        "print(\"Length of each sequence in input sequence: \", len(input_seq[0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of input characters:  562291\n",
            "Length of output sequence:  562291\n",
            "Length of each sequence in input sequence:  80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP0rJKordDHs"
      },
      "source": [
        "## Transforming the input and output sequences into one hot encoded vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFecV6OLdDHu"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(input_seq, (len(input_seq), window_len, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(len(unique_chars))\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(output_seq)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UINQOyxVdDHx"
      },
      "source": [
        "## Creating the sequential LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mip34IXdDHy"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxXDRFc2_6rr"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS1cIPkj__f5"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3xgIR6g-Fab"
      },
      "source": [
        "filepath=\"../logs/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hJ0fOzBdDH0",
        "outputId": "8d6f9e5f-9a2b-40b5-852a-303eb909f8d7"
      },
      "source": [
        "history_ = model.fit(X, y, epochs=25, batch_size=512, callbacks=callbacks_list)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1099/1099 [==============================] - 92s 82ms/step - loss: 3.0470\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.96716, saving model to ../logs/weights-improvement-01-2.9672.hdf5\n",
            "Epoch 2/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 2.6999\n",
            "\n",
            "Epoch 00002: loss improved from 2.96716 to 2.59922, saving model to ../logs/weights-improvement-02-2.5992.hdf5\n",
            "Epoch 3/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 2.3755\n",
            "\n",
            "Epoch 00003: loss improved from 2.59922 to 2.32802, saving model to ../logs/weights-improvement-03-2.3280.hdf5\n",
            "Epoch 4/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 2.2106\n",
            "\n",
            "Epoch 00004: loss improved from 2.32802 to 2.18634, saving model to ../logs/weights-improvement-04-2.1863.hdf5\n",
            "Epoch 5/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 2.1049\n",
            "\n",
            "Epoch 00005: loss improved from 2.18634 to 2.08840, saving model to ../logs/weights-improvement-05-2.0884.hdf5\n",
            "Epoch 6/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 2.0286\n",
            "\n",
            "Epoch 00006: loss improved from 2.08840 to 2.01492, saving model to ../logs/weights-improvement-06-2.0149.hdf5\n",
            "Epoch 7/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.9733\n",
            "\n",
            "Epoch 00007: loss improved from 2.01492 to 1.96363, saving model to ../logs/weights-improvement-07-1.9636.hdf5\n",
            "Epoch 8/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.9214\n",
            "\n",
            "Epoch 00008: loss improved from 1.96363 to 1.91869, saving model to ../logs/weights-improvement-08-1.9187.hdf5\n",
            "Epoch 9/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.8878\n",
            "\n",
            "Epoch 00009: loss improved from 1.91869 to 1.88594, saving model to ../logs/weights-improvement-09-1.8859.hdf5\n",
            "Epoch 10/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.8567\n",
            "\n",
            "Epoch 00010: loss improved from 1.88594 to 1.85739, saving model to ../logs/weights-improvement-10-1.8574.hdf5\n",
            "Epoch 11/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.8319\n",
            "\n",
            "Epoch 00011: loss improved from 1.85739 to 1.83044, saving model to ../logs/weights-improvement-11-1.8304.hdf5\n",
            "Epoch 12/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.8076\n",
            "\n",
            "Epoch 00012: loss improved from 1.83044 to 1.80785, saving model to ../logs/weights-improvement-12-1.8078.hdf5\n",
            "Epoch 13/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.7885\n",
            "\n",
            "Epoch 00013: loss improved from 1.80785 to 1.78641, saving model to ../logs/weights-improvement-13-1.7864.hdf5\n",
            "Epoch 14/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.7662\n",
            "\n",
            "Epoch 00014: loss improved from 1.78641 to 1.76970, saving model to ../logs/weights-improvement-14-1.7697.hdf5\n",
            "Epoch 15/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.7524\n",
            "\n",
            "Epoch 00015: loss improved from 1.76970 to 1.75270, saving model to ../logs/weights-improvement-15-1.7527.hdf5\n",
            "Epoch 16/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.7400\n",
            "\n",
            "Epoch 00016: loss improved from 1.75270 to 1.73888, saving model to ../logs/weights-improvement-16-1.7389.hdf5\n",
            "Epoch 17/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.7263\n",
            "\n",
            "Epoch 00017: loss improved from 1.73888 to 1.72664, saving model to ../logs/weights-improvement-17-1.7266.hdf5\n",
            "Epoch 18/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.7090\n",
            "\n",
            "Epoch 00018: loss improved from 1.72664 to 1.71198, saving model to ../logs/weights-improvement-18-1.7120.hdf5\n",
            "Epoch 19/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.6981\n",
            "\n",
            "Epoch 00019: loss improved from 1.71198 to 1.70095, saving model to ../logs/weights-improvement-19-1.7010.hdf5\n",
            "Epoch 20/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.6838\n",
            "\n",
            "Epoch 00020: loss improved from 1.70095 to 1.68965, saving model to ../logs/weights-improvement-20-1.6896.hdf5\n",
            "Epoch 21/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.6724\n",
            "\n",
            "Epoch 00021: loss improved from 1.68965 to 1.67775, saving model to ../logs/weights-improvement-21-1.6777.hdf5\n",
            "Epoch 22/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.6644\n",
            "\n",
            "Epoch 00022: loss improved from 1.67775 to 1.66807, saving model to ../logs/weights-improvement-22-1.6681.hdf5\n",
            "Epoch 23/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.6590\n",
            "\n",
            "Epoch 00023: loss improved from 1.66807 to 1.66065, saving model to ../logs/weights-improvement-23-1.6606.hdf5\n",
            "Epoch 24/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.6464\n",
            "\n",
            "Epoch 00024: loss improved from 1.66065 to 1.65033, saving model to ../logs/weights-improvement-24-1.6503.hdf5\n",
            "Epoch 25/25\n",
            "1099/1099 [==============================] - 89s 81ms/step - loss: 1.6364\n",
            "\n",
            "Epoch 00025: loss improved from 1.65033 to 1.64296, saving model to ../logs/weights-improvement-25-1.6430.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41ew-Z5i8ni4",
        "outputId": "06187218-34f4-4b7b-a53f-12a55df2a16b"
      },
      "source": [
        "history_.history"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [2.967164993286133,\n",
              "  2.599224805831909,\n",
              "  2.328023910522461,\n",
              "  2.1863412857055664,\n",
              "  2.088399648666382,\n",
              "  2.014918327331543,\n",
              "  1.9636296033859253,\n",
              "  1.918687343597412,\n",
              "  1.8859351873397827,\n",
              "  1.8573904037475586,\n",
              "  1.8304370641708374,\n",
              "  1.8078471422195435,\n",
              "  1.7864060401916504,\n",
              "  1.769704818725586,\n",
              "  1.7526977062225342,\n",
              "  1.7388808727264404,\n",
              "  1.726637363433838,\n",
              "  1.7119840383529663,\n",
              "  1.7009505033493042,\n",
              "  1.6896486282348633,\n",
              "  1.6777474880218506,\n",
              "  1.6680729389190674,\n",
              "  1.660649299621582,\n",
              "  1.650329828262329,\n",
              "  1.6429623365402222]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "xVLuRbsedDH3",
        "outputId": "754c5d94-0ef0-4dae-e2c2-f6265b8dbcb4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss = history_.history['loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Loss')\n",
        "plt.title('Loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kpedehL7OOjA",
        "outputId": "d7e2eed2-8381-4a06-ab97-47f865ad667c"
      },
      "source": [
        "start = np.random.randint(0, len(input_seq)-1)\n",
        "pattern = input_seq[start]\n",
        "''.join([int_to_char_dict[val] for val in pattern])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'t his whole debts at the present moment,\\nas far as we have been able to ascertai'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94sNCofH8aYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b20b568-be96-4a1a-fcf1-e5195db488b0"
      },
      "source": [
        "import sys\n",
        "for i in range(1000):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(len(unique_chars))\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char_dict[index]\n",
        "\tseq_in = [int_to_char_dict[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n the sort to the cort of the\n",
            "sorpner and the sore to the cort to the cort to the cort to the sore\n",
            "monty uoon the sort to the cort to the cort to the cort to the come of\n",
            "the sort to the cort to the cort to the cort to the cort to the sore\n",
            "monty uoon the sort to the cort to the cort to the cort to the come of\n",
            "the sort to the cort to the cort to the cort to the cort to the sore\n",
            "monty uoon the sort to the cort to the cort to the cort to the come of\n",
            "the sort to the cort to the cort to the cort to the cort to the sore\n",
            "monty uoon the sort to the cort to the cort to the cort to the come of\n",
            "the sort to the cort to the cort to the cort to the cort to the sore\n",
            "monty uoon the sort to the cort to the cort to the cort to the come of\n",
            "the sort to the cort to the cort to the cort to the cort to the sore\n",
            "monty uoon the sort to the cort to the cort to the cort to the come of\n",
            "the sort to the cort to the cort to the cort to the cort to the sore\n",
            "monty uoon the sort to the cort to the cort to the cort to th"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TkaPVJMOGOT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}